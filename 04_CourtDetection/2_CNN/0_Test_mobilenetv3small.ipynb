{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobilenetV3 Small\n",
    "\n",
    "In this notebook the MobilenetV3 Small with a fully connected head ist tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from court_dataset import CourtDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from CourtTrackNet import Court_TN\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenetv3small(num_coordinates=15):\n",
    "    # Load pretrained MobileNetV3-Small\n",
    "    model = models.mobilenet_v3_small(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # Extract the number of features output by the last convolutional layer\n",
    "    num_features = model.classifier[0].in_features  # Fixed to handle changes in feature size dynamically\n",
    "    \n",
    "    # Modify the classification head\n",
    "    num_outputs = num_coordinates * 2  # Each coordinate has (x, y)\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),  # Hidden layer\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, num_outputs)  # Output layer for coordinates\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device, epoch, criterion=torch.nn.MSELoss()):\n",
    "    start_time = time.time()\n",
    "    losses = []\n",
    "\n",
    "    # Wrap train_loader with tqdm for a progress bar\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\") as pbar:\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "\n",
    "            # Forward pass\n",
    "            inputs = batch[0].float().to(device)  # Input frames (images)\n",
    "            keypoints_gt = batch[1].float().to(device)  # Ground truth keypoints\n",
    "            outputs = model(inputs)  # Predicted keypoints\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, keypoints_gt.view(outputs.size()))  # Match shapes for regression\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track losses\n",
    "            losses.append(loss.item())\n",
    "            duration = time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time))\n",
    "\n",
    "            # Update the tqdm bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': round(loss.item(), 6),\n",
    "                'time': duration\n",
    "            })\n",
    "            pbar.update(1)\n",
    "            \n",
    "    return np.mean(losses)\n",
    "\n",
    "def compute_mse(points, positions, img_size):\n",
    "    #loop over points\n",
    "    mse = []\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        # get the point\n",
    "        point = points[i]\n",
    "        # get the position\n",
    "        position = positions[i]\n",
    "\n",
    "        # if the point is outside the image, skip\n",
    "        if point[0] < 0 or point[0] >= img_size[0] or point[1] < 0 or point[1] >= img_size[1]:\n",
    "            continue\n",
    "\n",
    "        # if the position is -1,-1 return the maximum distance\n",
    "        if position[0] == -1 and position[1] == -1:\n",
    "            continue\n",
    "        \n",
    "        # calculate the distance\n",
    "        distance = np.linalg.norm(np.array(point) - np.array(position))\n",
    "\n",
    "        # add to mse\n",
    "        mse.append(distance**2)\n",
    "\n",
    "    # return the mean\n",
    "    return np.mean(mse)\n",
    "\n",
    "\n",
    "def compute_counts(points, positions, img_size, threshold=4):\n",
    "    # check that len is the same\n",
    "    assert len(points) == len(positions) \n",
    "    \n",
    "    #loop over points\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        # get the point\n",
    "        point = points[i]\n",
    "        # get the position\n",
    "        position = positions[i]\n",
    "        \n",
    "        # calculate the distance\n",
    "        distance = np.linalg.norm(np.array(point) - np.array(position))\n",
    "\n",
    "        # add to tp, fp, fn, tn\n",
    "        if distance <= threshold:\n",
    "            # if point is outside the frame\n",
    "            if point[0] < 0 or point[0] >= img_size[0] or point[1] < 0 or point[1] >= img_size[1]:\n",
    "                tn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "        else:\n",
    "            #if point is outside the frame\n",
    "            if point[0] < 0 or point[0] >= img_size[0] or point[1] < 0 or point[1] >= img_size[1]:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "    # return the metrics\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "\n",
    "def calculate_metrics(tp, fp, tn, fn):\n",
    "    # Avoid division by zero for precision and recall\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "    # F1-score calculation\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    # Accuracy calculation\n",
    "    total = tp + fp + tn + fn\n",
    "    accuracy = (tp + tn) / total if total > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "\n",
    "def validate(model, val_loader, device, criterion=torch.nn.MSELoss(), threshold=4, img_size=(1280, 720)):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0  # Initialize counts\n",
    "    losses = []\n",
    "    mse_scores = []\n",
    "\n",
    "    with tqdm(total=len(val_loader), desc=\"Validation\", unit=\"batch\") as pbar:\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            with torch.no_grad():\n",
    "                # Prepare data\n",
    "                inputs = batch[0].float().to(device)  # Input images\n",
    "                keypoints_gt = batch[1].float().to(device)  # Ground truth keypoints\n",
    "                outputs = model(inputs)  # Predicted keypoints\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = criterion(outputs, keypoints_gt.view(outputs.size()))  # Match shapes for regression\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # First loop: Iterate over each item in the batch\n",
    "                for i in range(outputs.shape[0]):  # Loop over batch samples\n",
    "                    # get predictions\n",
    "                    positions = outputs[i].view(-1, 2).cpu().numpy()\n",
    "                    # move to cpu\n",
    "                    keypoints = keypoints_gt[i].cpu().numpy()\n",
    "                    \n",
    "                    #Compute MSE for the batch\n",
    "                    mse = compute_mse(keypoints, positions, img_size)\n",
    "                    mse_scores.append(mse)\n",
    "\n",
    "                    # Compute TP, FP, TN, FN for the batch\n",
    "                    item_tp, item_fp, item_tn, item_fn = compute_counts(keypoints, positions, img_size, threshold)\n",
    "                    tp += item_tp\n",
    "                    fp += item_fp\n",
    "                    tn += item_tn\n",
    "                    fn += item_fn\n",
    "\n",
    "                # Update the tqdm bar\n",
    "                pbar.set_postfix({\n",
    "                    'loss': round(np.mean(losses), 6)\n",
    "                })\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    mean_loss = np.mean(losses)\n",
    "    mean_mse = np.mean(mse_scores)\n",
    "    metrics = calculate_metrics(tp, fp, tn, fn)\n",
    "\n",
    "    return mean_loss, mean_mse, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def setup_paths(exp_id):\n",
    "    exps_path = f'./exps/{exp_id}'\n",
    "    if not os.path.exists(exps_path):\n",
    "        os.makedirs(exps_path)\n",
    "    \n",
    "    paths = {\n",
    "        \"model_last\": os.path.join(exps_path, 'model_last.pth'),\n",
    "        \"model_best\": os.path.join(exps_path, 'model_best.pth'),\n",
    "        \"log\": os.path.join(exps_path, 'training_log.txt')\n",
    "    }\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(dataset_path, batch_size):\n",
    "    train_dataset = CourtDataset(\n",
    "        path=dataset_path,\n",
    "        split=\"train\",\n",
    "        input_height=720,\n",
    "        input_width=1280,\n",
    "        model_height=288,\n",
    "        model_width=512,\n",
    "        augment=True,\n",
    "        selected_points=None\n",
    "    )\n",
    "    \n",
    "    val_dataset = CourtDataset(\n",
    "        path=dataset_path,\n",
    "        split=\"validation\",\n",
    "        input_height=720,\n",
    "        input_width=1280,\n",
    "        model_height=288,\n",
    "        model_width=512,\n",
    "        augment=False,\n",
    "        selected_points=None\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training():\n",
    "    set_seed(SEED)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    no_improvement_steps = 0  \n",
    "    val_intervals = 2\n",
    "    selected_gpus = [0,1]\n",
    "    patience = 10 \n",
    "    dataset_path = \"../../00_Dataset\"\n",
    "    batch_size = 64\n",
    "    num_coordinates = 15  # Number of keypoints\n",
    "    num_epochs = 100\n",
    "    learning_rate = 1e-3\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    #create name based aon augment, input and output number\n",
    "    exp_id = \"CourtMobileNetv3_test\"\n",
    "    \n",
    "    # Set up paths for experiment and logging\n",
    "    paths = setup_paths(exp_id)\n",
    "\n",
    "    # Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Start logging to a file\n",
    "    with open(paths[\"log\"], 'w') as log_file:\n",
    "        log_file.write(\"Epoch,Train_Loss,Val_Loss,MSED,Accuracy,F1\\n\")\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader, val_loader = create_dataloaders(dataset_path, batch_size)\n",
    "\n",
    "        # Set up the model\n",
    "        # Model setup\n",
    "        model = create_mobilenetv3small(num_coordinates=num_coordinates)\n",
    "        model = nn.DataParallel(model, device_ids=selected_gpus)\n",
    "        model = model.to(f'cuda:{selected_gpus[0]}')\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.1, patience=3\n",
    "        )\n",
    "\n",
    "        # Set the primary device (first GPU in the list)\n",
    "        device = torch.device(f'cuda:{selected_gpus[0]}')\n",
    "        \n",
    "        # train epochs\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # set epoch seed\n",
    "            set_seed(SEED + epoch)\n",
    "            \n",
    "            # Training step\n",
    "            train_loss = train(model, train_loader, optimizer, device, epoch, criterion=criterion)\n",
    "            log_file.write(f\"{epoch},{train_loss}\")\n",
    "\n",
    "            # Validation step\n",
    "            if epoch > 0 and epoch % val_intervals == 0:\n",
    "                val_loss, mean_mse, metrics = validate(model, val_loader, device, criterion=criterion)\n",
    "                log_file.write(f\",{val_loss},{mean_mse},{metrics['accuracy']},{metrics['f1']}\\n\")\n",
    "\n",
    "                # Step the scheduler based on validation loss\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "                # Save the best model\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    no_improvement_steps = 0  # Reset counter\n",
    "                    #save model\n",
    "                    torch.save(model.module.state_dict(), paths[\"model_best\"])\n",
    "                else:\n",
    "                    no_improvement_steps += 1  # Increment counter\n",
    "\n",
    "                # Early stopping check\n",
    "                if no_improvement_steps >= patience:\n",
    "                    print(\"Early stopping triggered. No improvement in validation for\", patience, \"validation steps.\")\n",
    "                    break\n",
    "            else:\n",
    "                log_file.write(\"\\n\")  # Log training loss only if no validation\n",
    "\n",
    "            # Save the latest model checkpoint\n",
    "            torch.save(model.module.state_dict(), paths[\"model_last\"])\n",
    "\n",
    "        return paths[\"model_best\"]\n",
    "\n",
    "def load_model(best_model_path):\n",
    "    num_coordinates = 15\n",
    "    selected_gpus = [0,1]\n",
    "    device = torch.device(f'cuda:{selected_gpus[0]}')\n",
    "    \n",
    "    # Recreate the model architecture\n",
    "    model = create_mobilenetv3small(num_coordinates=num_coordinates)\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model = model.to(f'cuda:{selected_gpus[0]}')\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    print(f\"Model loaded from: {best_model_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = training()\n",
    "model = load_model(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_val_image(model, val_loader, device, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Select a random batch from the DataLoader\n",
    "    random_batch_idx = random.randint(0, len(val_loader) - 1)\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        if i == random_batch_idx:\n",
    "            inputs, keypoints_gt = batch[0], batch[1]\n",
    "            break\n",
    "\n",
    "    # Select a random sample from the batch\n",
    "    idx = random.randint(0, inputs.size(0) - 1)\n",
    "    input_image = inputs[idx].to(device).unsqueeze(0)  # Select image, add batch dimension\n",
    "    ground_truth = keypoints_gt[idx].cpu().numpy()  # Ground truth keypoints\n",
    "\n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_image).view(-1, 2).cpu().numpy()  # Predicted keypoints\n",
    "\n",
    "    # Convert the image for visualization\n",
    "    img = inputs[idx].permute(1, 2, 0).cpu().numpy()  # Convert (C, H, W) to (H, W, C)\n",
    "\n",
    "    # De-normalize the image\n",
    "    img = img * std + mean  # Reverse normalization\n",
    "    img = np.clip(img, 0, 1)  # Ensure pixel values are in range [0, 1]\n",
    "    img = (img * 255).astype(\"uint8\")  # Convert to [0, 255] range for visualization\n",
    "\n",
    "    # Plot the image\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.scatter(ground_truth[:, 0], ground_truth[:, 1], c=\"green\", label=\"Ground Truth\", s=40)\n",
    "    plt.scatter(predictions[:, 0], predictions[:, 1], c=\"red\", label=\"Prediction\", s=40)\n",
    "    plt.legend()\n",
    "    plt.title(f\"Random Validation Image\\nGreen: Ground Truth, Red: Prediction\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Set the primary device (first GPU in the list)\n",
    "train_loader, val_loader = create_dataloaders(\"../../00_Dataset\", 32)\n",
    "selected_gpus = [0,1]\n",
    "device = torch.device(f'cuda:{selected_gpus[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_val_image(model, val_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BV_Conda",
   "language": "python",
   "name": "bv_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
