{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3090ee6b",
   "metadata": {},
   "source": [
    "# Evaluation Results\n",
    "\n",
    "In This notebook the results on the test set are generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe31bcb",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f1135d-386a-4cd6-9ce8-d7e7879a7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from DatasetEval import BallDataSet\n",
    "from BallTrackNet import BallTrackNet\n",
    "from helpers import train, validate, WeightedBCELoss, BinaryFocalLoss\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "import json\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422414a4",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fbf8a9-389c-4571-ba05-a5d22e69f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Unpack batch into respective components\n",
    "    images, heatmaps, points, dataframes = zip(*batch)\n",
    "    \n",
    "    # Stack tensors for images, heatmaps, points, and indices\n",
    "    images = torch.stack(images)\n",
    "    heatmaps = torch.stack(heatmaps)\n",
    "    points = torch.stack(points)\n",
    "    \n",
    "    return images, heatmaps, points, list(dataframes)\n",
    "\n",
    "def create_dataloader(path, heatmap_size, input_number, output_number, batch_size):\n",
    "    \n",
    "    test = BallDataSet(path=path, split='test', heatmap_size=heatmap_size, input_size=input_number, output_size=output_number, recreate_heatmap=False)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=4,\n",
    "        collate_fn=custom_collate\n",
    "    )\n",
    "\n",
    "    return test, test_loader\n",
    "\n",
    "def load_model(path, input_size, output_size, gpus):\n",
    "    model = BallTrackNet(input_size=input_size, output_size=output_size)\n",
    "    model = nn.DataParallel(model, device_ids=gpus)\n",
    "    model = model.to(f'cuda:{gpus[0]}')\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea45229-cb25-450a-867d-1ff10ce5a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_position(output, threshold):\n",
    "    # Binarize the heatmap\n",
    "    binary_map = (output > threshold).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    # Perform connected component analysis\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_map, connectivity=8)\n",
    "\n",
    "    if num_labels > 1:  # Exclude background label 0\n",
    "        # Find the largest region (excluding background label 0)\n",
    "        largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])  # Index 1 is the first component\n",
    "        largest_centroid = centroids[largest_label]\n",
    "        return int(largest_centroid[0]), int(largest_centroid[1])\n",
    "    else:\n",
    "        # No region found\n",
    "        return -1, -1\n",
    "    \n",
    "\n",
    "def calculate_frame_metrics(predicted_point, ground_truth_point, min_dist=4):\n",
    "    # Check if both predicted and ground truth points are valid\n",
    "    if predicted_point != (-1, -1) and ground_truth_point != (-1, -1):\n",
    "        # Calculate distance\n",
    "        if distance.euclidean(predicted_point, ground_truth_point) < min_dist:\n",
    "            return (\"tp\")               # True Positive: Prediction matches ground truth\n",
    "        else:\n",
    "            return (\"fp\")               # False Positive: Prediction exists but doesn't match ground truth\n",
    "    elif predicted_point != (-1, -1):\n",
    "        return (\"fp\")                   # False Positive: Prediction exists but no ground truth\n",
    "    elif ground_truth_point != (-1, -1):\n",
    "        return (\"fn\")                   # False Negative: Ground truth exists but no prediction\n",
    "    else:\n",
    "        return (\"tn\")                   # True Negative: Neither prediction nor ground truth exists\n",
    "\n",
    "\n",
    "def calculate_metrics(stats):\n",
    "    tp = stats.get(\"tp\", 0)\n",
    "    tn = stats.get(\"tn\", 0)\n",
    "    fp = stats.get(\"fp\", 0)\n",
    "    fn = stats.get(\"fn\", 0)\n",
    "\n",
    "    # Avoid division by zero with if \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn ) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def tensor_to_point(gt_point):\n",
    "    # Convert tensor([x], [y]) to (x, y)\n",
    "    if isinstance(gt_point, list) or isinstance(gt_point, tuple):\n",
    "        return tuple(p.item() for p in gt_point)\n",
    "    elif isinstance(gt_point, torch.Tensor):\n",
    "        return tuple(gt_point.tolist())\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported ground truth format\")\n",
    "\n",
    "\n",
    "def validate(model, test_loader, device, min_dist=4, threshold=0.5, criterion=WeightedBCELoss()):\n",
    "    losses = []\n",
    "    # Create a dictionary for tp, tn, fp, fn\n",
    "    stats = {\"tp\": 0, \"tn\": 0, \"fp\": 0, \"fn\": 0}\n",
    "\n",
    "    # Store predictions and ground truth for each frame\n",
    "    frame_results = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Wrap val_loader with tqdm for a progress bar\n",
    "    with tqdm(total=len(test_loader), desc=\"Validation\", unit=\"batch\") as pbar:\n",
    "        for iter_id, batch in enumerate(test_loader):\n",
    "            with torch.no_grad():\n",
    "                inputs = batch[0].float().to(device)  # Input frames\n",
    "                heatmap = batch[1].float().to(device)  # Ground truth heatmap\n",
    "                points = batch[2]  # Ground truth ball positions\n",
    "                dataframes_batch = batch[3]\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, heatmap)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                for batch_idx in range(outputs.shape[0]):\n",
    "                    dataframe_entries = dataframes_batch[batch_idx].reset_index(drop=True)\n",
    "                    elements_to_skip = outputs[batch_idx].shape[0]- len(dataframe_entries)\n",
    "                    counter = 0\n",
    "                    for frame_idx in range(outputs[batch_idx].shape[0]):\n",
    "                        \n",
    "                        # Process each batch separately\n",
    "                        output = outputs[batch_idx][frame_idx]\n",
    "                        gt_point = points[batch_idx][frame_idx]\n",
    "\n",
    "                        #  get correct entry\n",
    "                        if elements_to_skip > 0:\n",
    "                            entry = None\n",
    "                            elements_to_skip -= 1\n",
    "                        else:\n",
    "                            entry = dataframe_entries.iloc[counter]\n",
    "                            counter += 1\n",
    "\n",
    "                        gt_point_formatted = tensor_to_point(gt_point) \n",
    "\n",
    "                        # Calculate predicted position for the frame\n",
    "                        predicted_position = calculate_position(output, threshold)\n",
    "\n",
    "                        case = calculate_frame_metrics(predicted_position, gt_point_formatted, min_dist)\n",
    "\n",
    "                        # Update stats\n",
    "                        stats[case] += 1\n",
    "\n",
    "                        if entry is not None:\n",
    "                            # Append results for this frame\n",
    "                            frame_results.append({\n",
    "                                'subset': entry['subset'],\n",
    "                                'video': entry['video'],\n",
    "                                'clip': entry['clip'],\n",
    "                                'frame': entry['frame'],\n",
    "                                'points': entry['points'],\n",
    "                                'window_index': entry['window_index'],\n",
    "                                \"predicted_position\": predicted_position,\n",
    "                                \"ground_truth_position\": gt_point_formatted\n",
    "                            })\n",
    "\n",
    "                # Update the tqdm bar\n",
    "                pbar.set_postfix({'loss': round(np.mean(losses), 6)})\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(stats)\n",
    "\n",
    "    return np.mean(losses), accuracy, precision, recall, f1, frame_results\n",
    "\n",
    "def calculate_computation_time(test_loader, device, model):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    start_time = time.time()  # Record the start time\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch[0].float().to(device)  # Input frames\n",
    "            outputs = model(inputs)  # Perform inference\n",
    "    \n",
    "    end_time = time.time()  # Record the end time\n",
    "\n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    return elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0320743-17ef-45a1-a160-504e0b1cfdf6",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd0f3a2-9f75-4d5f-9d37-3501279246d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus=[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ef548-5483-4df6-94b6-5dcf99fbfe15",
   "metadata": {},
   "source": [
    "## Create Results DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebf0b1f1-fa2e-46f3-b300-b72dc33c9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Test_Results(gpus, input_size = 3, output_size=3, augmented = True):\n",
    "    dataset, test_dataloader = create_dataloader(path= \"../FinalDataset\", heatmap_size = 10, input_number=input_size, output_number=output_size, batch_size=32)\n",
    "    \n",
    "    path = f\"exps/TrackNet_{input_size}-in-{output_size}-out_aug_{augmented}/model_best.pt\"\n",
    "    \n",
    "    model = load_model(path=path, input_size=input_size, output_size=output_size, gpus=gpus)\n",
    "    \n",
    "    test_loss, accuracy, precision, recall, f1, frame_results = validate(model, test_dataloader, device=gpus[0])\n",
    "\n",
    "    comp_time = calculate_computation_time(test_loader=test_dataloader , device=gpus[0], model=model)\n",
    "    fps = 2877 / comp_time\n",
    "\n",
    "    return test_loss, accuracy, precision, recall, f1, comp_time, fps, frame_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e61d972e-a683-47f6-a3cd-c07a47810c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1150873/1507865041.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: 961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 31/31 [00:12<00:00,  2.53batch/s, loss=4.75e+3]\n",
      "/tmp/ipykernel_1150873/1507865041.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: 961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 31/31 [00:10<00:00,  2.90batch/s, loss=4.16e+3]\n",
      "/tmp/ipykernel_1150873/1507865041.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: 2877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 90/90 [00:24<00:00,  3.75batch/s, loss=1.8e+3] \n",
      "/tmp/ipykernel_1150873/1507865041.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: 2877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 90/90 [00:23<00:00,  3.79batch/s, loss=2.29e+3]\n",
      "/tmp/ipykernel_1150873/1507865041.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: 961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 31/31 [00:14<00:00,  2.13batch/s, loss=4.22e+3]\n",
      "/tmp/ipykernel_1150873/1507865041.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: 961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 31/31 [00:11<00:00,  2.78batch/s, loss=4.89e+3]\n",
      "/tmp/ipykernel_1150873/1507865041.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 19/19 [00:08<00:00,  2.17batch/s, loss=8.5e+3] \n",
      "/tmp/ipykernel_1150873/1507865041.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 19/19 [00:08<00:00,  2.18batch/s, loss=6.63e+3]\n"
     ]
    }
   ],
   "source": [
    "versions = [\n",
    "        {\"augmentation\": True, \"input_number\": 3, \"output_number\": 3},\n",
    "        {\"augmentation\": False, \"input_number\": 3, \"output_number\": 3},\n",
    "        {\"augmentation\": True, \"input_number\": 3, \"output_number\": 1},\n",
    "        {\"augmentation\": False, \"input_number\": 3, \"output_number\": 1},\n",
    "        {\"augmentation\": True, \"input_number\": 5, \"output_number\": 3},\n",
    "        {\"augmentation\": False, \"input_number\": 5, \"output_number\": 3},\n",
    "        {\"augmentation\": True, \"input_number\": 5, \"output_number\": 5},\n",
    "        {\"augmentation\": False, \"input_number\": 5, \"output_number\": 5}\n",
    "    ]\n",
    "\n",
    "all_results = []\n",
    "for version in versions:\n",
    "    test_loss, accuracy, precision, recall, f1, comp_time, fps, frame_results = get_Test_Results(input_size = version[\"input_number\"], output_size=version[\"output_number\"], augmented = version[\"augmentation\"], gpus = gpus)\n",
    "\n",
    "    # create object for results\n",
    "    results = {\n",
    "        \"version\": version,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"time\": comp_time,\n",
    "        \"fps\": fps,\n",
    "        \"frame_results\": frame_results\n",
    "    }\n",
    "\n",
    "    all_results.append(results)\n",
    "    \n",
    "df_results = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2615f33-57be-46ca-a707-8b5603b8ddb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'augmentation': True, 'input_number': 3, 'out...</td>\n",
       "      <td>4753.948033</td>\n",
       "      <td>0.872008</td>\n",
       "      <td>0.942683</td>\n",
       "      <td>0.901578</td>\n",
       "      <td>0.921673</td>\n",
       "      <td>8.694051</td>\n",
       "      <td>330.915950</td>\n",
       "      <td>[{'subset': 'New', 'video': 'Video_1', 'clip':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'augmentation': False, 'input_number': 3, 'ou...</td>\n",
       "      <td>4161.026125</td>\n",
       "      <td>0.851197</td>\n",
       "      <td>0.923313</td>\n",
       "      <td>0.892418</td>\n",
       "      <td>0.907603</td>\n",
       "      <td>8.861190</td>\n",
       "      <td>324.674231</td>\n",
       "      <td>[{'subset': 'New', 'video': 'Video_1', 'clip':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'augmentation': True, 'input_number': 3, 'out...</td>\n",
       "      <td>1795.755328</td>\n",
       "      <td>0.861661</td>\n",
       "      <td>0.946661</td>\n",
       "      <td>0.883312</td>\n",
       "      <td>0.913890</td>\n",
       "      <td>21.285650</td>\n",
       "      <td>135.161485</td>\n",
       "      <td>[{'subset': 'New', 'video': 'Video_1', 'clip':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'augmentation': False, 'input_number': 3, 'ou...</td>\n",
       "      <td>2292.572355</td>\n",
       "      <td>0.808481</td>\n",
       "      <td>0.901713</td>\n",
       "      <td>0.857265</td>\n",
       "      <td>0.878928</td>\n",
       "      <td>21.145362</td>\n",
       "      <td>136.058206</td>\n",
       "      <td>[{'subset': 'New', 'video': 'Video_1', 'clip':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'augmentation': True, 'input_number': 5, 'out...</td>\n",
       "      <td>4217.184523</td>\n",
       "      <td>0.829344</td>\n",
       "      <td>0.905800</td>\n",
       "      <td>0.882703</td>\n",
       "      <td>0.894102</td>\n",
       "      <td>9.226051</td>\n",
       "      <td>311.834388</td>\n",
       "      <td>[{'subset': 'New', 'video': 'Video_1', 'clip':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'augmentation': False, 'input_number': 5, 'ou...</td>\n",
       "      <td>4885.998479</td>\n",
       "      <td>0.865765</td>\n",
       "      <td>0.946089</td>\n",
       "      <td>0.889859</td>\n",
       "      <td>0.917113</td>\n",
       "      <td>9.441132</td>\n",
       "      <td>304.730405</td>\n",
       "      <td>[{'subset': 'New', 'video': 'Video_1', 'clip':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'augmentation': True, 'input_number': 5, 'out...</td>\n",
       "      <td>8495.575709</td>\n",
       "      <td>0.880690</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>0.897489</td>\n",
       "      <td>0.926477</td>\n",
       "      <td>6.421600</td>\n",
       "      <td>448.019195</td>\n",
       "      <td>[{'subset': 'New', 'video': 'Video_1', 'clip':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'augmentation': False, 'input_number': 5, 'ou...</td>\n",
       "      <td>6633.399764</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.928326</td>\n",
       "      <td>0.903132</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>6.857523</td>\n",
       "      <td>419.539229</td>\n",
       "      <td>[{'subset': 'New', 'video': 'Video_1', 'clip':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             version    test_loss  accuracy  \\\n",
       "0  {'augmentation': True, 'input_number': 3, 'out...  4753.948033  0.872008   \n",
       "1  {'augmentation': False, 'input_number': 3, 'ou...  4161.026125  0.851197   \n",
       "2  {'augmentation': True, 'input_number': 3, 'out...  1795.755328  0.861661   \n",
       "3  {'augmentation': False, 'input_number': 3, 'ou...  2292.572355  0.808481   \n",
       "4  {'augmentation': True, 'input_number': 5, 'out...  4217.184523  0.829344   \n",
       "5  {'augmentation': False, 'input_number': 5, 'ou...  4885.998479  0.865765   \n",
       "6  {'augmentation': True, 'input_number': 5, 'out...  8495.575709  0.880690   \n",
       "7  {'augmentation': False, 'input_number': 5, 'ou...  6633.399764  0.862414   \n",
       "\n",
       "   precision    recall        f1       time         fps  \\\n",
       "0   0.942683  0.901578  0.921673   8.694051  330.915950   \n",
       "1   0.923313  0.892418  0.907603   8.861190  324.674231   \n",
       "2   0.946661  0.883312  0.913890  21.285650  135.161485   \n",
       "3   0.901713  0.857265  0.878928  21.145362  136.058206   \n",
       "4   0.905800  0.882703  0.894102   9.226051  311.834388   \n",
       "5   0.946089  0.889859  0.917113   9.441132  304.730405   \n",
       "6   0.957400  0.897489  0.926477   6.421600  448.019195   \n",
       "7   0.928326  0.903132  0.915556   6.857523  419.539229   \n",
       "\n",
       "                                       frame_results  \n",
       "0  [{'subset': 'New', 'video': 'Video_1', 'clip':...  \n",
       "1  [{'subset': 'New', 'video': 'Video_1', 'clip':...  \n",
       "2  [{'subset': 'New', 'video': 'Video_1', 'clip':...  \n",
       "3  [{'subset': 'New', 'video': 'Video_1', 'clip':...  \n",
       "4  [{'subset': 'New', 'video': 'Video_1', 'clip':...  \n",
       "5  [{'subset': 'New', 'video': 'Video_1', 'clip':...  \n",
       "6  [{'subset': 'New', 'video': 'Video_1', 'clip':...  \n",
       "7  [{'subset': 'New', 'video': 'Video_1', 'clip':...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d59dbd-7b30-4b60-bfad-e4ef69f3eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"../results/Pre_Results_TN.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BV_Conda",
   "language": "python",
   "name": "bv_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
